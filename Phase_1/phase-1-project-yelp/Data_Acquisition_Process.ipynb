{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Your Data From Yelp!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make sure you are on track to completing the project, you will complete this workbook first. Below are steps that you need to take in order to make sure you have your data from yelp and are ready to analyze it. Your cohort lead will review this workbook with you the Wednesday before your project is due.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Understanding your data and question\n",
    "\n",
    "You will be pulling data from the Yelp API to complete your analysis. The api, however, provides you with a lot of information that will not be pertinent to your analysis. YOu will pull data from the api and parse through it to keep only the data that you will need. In order to help you identify that information,look at the API documentation and understand what data the api will provide you. \n",
    "\n",
    "Identify which data fields you will want to keep for your analysis. \n",
    "\n",
    "https://www.yelp.com/developers/documentation/v3/get_started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Create ETL pipeline for the business data from the API\n",
    "\n",
    "Now that you know what data you need from the API, you want to write code that will execute a api call, parse those results and then insert the results into the DB.  \n",
    "\n",
    "It is helpful to break this up into three different functions (*api call, parse results, and insert into DB*) and then you can write a function/script that pull the other three functions together. \n",
    "\n",
    "Let's first do this for the Business endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a function to make a call to the yelp API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../ds-apis-nbz32-main/.secrets/creds.json') as f:\n",
    "    creds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = creds['key']\n",
    "term = 'bike'\n",
    "location = 'Manhattan NY'\n",
    "SEARCH_LIMIT = 5\n",
    "url_params = {\n",
    "        'term': term.replace(' ', '+'),\n",
    "        'location': location.replace(' ', '+'),\n",
    "        'limit': SEARCH_LIMIT,\n",
    "        'offset': 0 \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yelp_call(url_params, api_key):\n",
    "    url = 'https://api.yelp.com/v3/businesses/search'\n",
    "    headers = {'Authorization': 'Bearer ' + api_key}\n",
    "    \n",
    "    data = requests.get(url, headers = headers, params = url_params)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = yelp_call(url_params, api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a function to parse the API response so that you can easily insert the data in to the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results(results):\n",
    "    # your code to parse the result to make them easier to insert into the DB\n",
    "    results = results.json()['businesses']\n",
    "    parsed_data = []\n",
    "    for business in results:\n",
    "        if 'price' not in business:\n",
    "            biz_info = (business['id'], business['name'], business['is_closed'],\n",
    "                business['review_count'], business['rating'], 'NaN',\n",
    "                business['location']['zip_code'])\n",
    "            parsed_data.append(biz_info)\n",
    "        else:\n",
    "            biz_info = (business['id'], business['name'], business['is_closed'],\n",
    "                business['review_count'], business['rating'], business['price'],\n",
    "                business['location']['zip_code'])\n",
    "            parsed_data.append(biz_info)\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#biker_df = pd.DataFrame(parse_results(results), columns = ('ID', 'Name', 'Is_Closed',\n",
    "#                                           'Review_Count', 'Rating', 'Price',\n",
    "#                                           'Zip_Code'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a function to take your parsed data and add it to the csv file where you will store all of your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#biker_df.to_csv('C:/Users/IM/Documents/Flatiron/ds-east-042621-lectures/Phase_1/phase-1-project-yelp/bikedata.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_results = parse_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Y2vbaQdhP6ALJrhGYpkFQg',\n",
       "  'Kickstand Bicycles',\n",
       "  False,\n",
       "  161,\n",
       "  5.0,\n",
       "  '$$',\n",
       "  '10017'),\n",
       " ('n4YHCDxWp07DicFxOcLzlw', 'Bicycles NYC', False, 125, 4.0, '$$$', '10075'),\n",
       " ('XnBflxEeUp0C-MefpSSTMg', 'Liberty Cycles', False, 170, 4.5, '$', '10019'),\n",
       " ('HdEwDk5wyjaLIvuhG9Awrw',\n",
       "  'New Bo Bo Bicycle',\n",
       "  False,\n",
       "  116,\n",
       "  5.0,\n",
       "  '$',\n",
       "  '10013'),\n",
       " ('wN6qVSygUdRPWblnyqW3mQ',\n",
       "  'Master Bike Shop',\n",
       "  False,\n",
       "  144,\n",
       "  4.0,\n",
       "  '$$',\n",
       "  '10023')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_safe(csv_filepath, parsed_results):\n",
    "    # your code to open the csv file, concat the current data, and save the data. \n",
    "    parsed_results = pd.DataFrame(parsed_results)\n",
    "    return parsed_results.to_csv(csv_filepath, mode = 'a', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filepath = 'C:/Users/IM/Documents/Flatiron/Phase_1_Project/new_york_bike_data.csv'\n",
    "t_ = df_safe(csv_filepath, parsed_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a script that combines the three functions above into a single process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it will take some experimentation to write the functions above, once you get them working it will be best to put them in a `.py` file and then import the functions to use in a script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helper_funcs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-1a21639612d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhelper_funcs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'helper_funcs'"
     ]
    }
   ],
   "source": [
    "from helper_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-50bf3fe14f3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#set up a while loop to go through and grab the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mwhile\u001b[0m \u001b[0mcur\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcur\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m#set the offset parameter to be where you currently are in the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0murl_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'offset'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# create a variable  to keep track of which result you are in. \n",
    "cur = 0\n",
    "\n",
    "#set up a while loop to go through and grab the result \n",
    "while cur < num and cur < 1000:\n",
    "    #set the offset parameter to be where you currently are in the results \n",
    "    url_params['offset'] = cur\n",
    "    #make your API call with the new offset number\n",
    "    results = yelp_call(url_params, api_key)\n",
    "    \n",
    "    #after you get your results you can now use your function to parse those results\n",
    "    parsed_results = parse_results(results)\n",
    "    \n",
    "    # use your function to insert your parsed results into the db\n",
    "    df_save(parsed_results)\n",
    "    #increment the counter by 50 to move on to the next results\n",
    "    cur += 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 -  Create ETL pipeline for the restaurant review data from the API\n",
    "\n",
    "You've done this for the Businesses, now you need to do this for reviews. You will follow the same process, but your functions will be specific to reviews. Above you ahve a model of the functions you will need to write, and how to pull them together in one script. For this part, you ahve the process below "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to pull the reveiws, you will need the business ids. So your first step will be to get all of the business ids from your businesses csv. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a function that takes a business id and makes a call to the API for reivews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a function to parse out the relevant information from the reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a function to save the parse data into a csv file containing all of the reviews. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Combine the functions above into a single script  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 -  Using python and pandas, write code to answer the questions below. \n",
    "\n",
    "\n",
    "- Which are the 5 most reviewed businesses in your dataset?\n",
    "- What is the highest rating recieved in your data set and how many businesses have that rating?\n",
    "- What percentage of businesses have a rating greater than or  4.5?\n",
    "- What percentage of businesses have a rating less than 3?\n",
    "- What percentage of your businesseshave a price label of one dollar sign? Two dollar signs? Three dollar signs? No dollar signs?\n",
    "- Return the text of the reviews for the most reviewed business. \n",
    "- Find the highest rated business and return text of the most recent review. If multiple business have the same rating, select the business with the most reviews. \n",
    "- Find the lowest rated business and return text of the most recent review.  If multiple business have the same rating, select the business with the least reviews. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Pagination\n",
    "\n",
    "Returning to the Yelp API, the [documentation](https://www.yelp.com/developers/documentation/v3/business_search) also provides us details regarding the API limits. These often include details about the number of requests a user is allowed to make within a specified time limit and the maximum number of results to be returned. In this case, we are told that any request has a maximum of 50 results per request and defaults to 20. Furthermore, any search will be limited to a total of 1000 results. To retrieve all 1000 of these results, we would have to page through the results piece by piece, retriving 50 at a time. Processes such as these are often refered to as pagination.\n",
    "\n",
    "Now that you have an initial response, you can examine the contents of the json container. For example, you might start with ```response.json().keys()```. Here, you'll see a key for `'total'`, which tells you the full number of matching results given your query parameters. Write a loop (or ideally a function) which then makes successive API calls using the offset parameter to retrieve all of the results (or 5000 for a particularly large result set) for the original query. As you do this, be mindful of how you store the data. \n",
    "\n",
    "**Note: be mindful of the API rate limits. You can only make 5000 requests per day, and APIs can make requests too fast. Start prototyping small before running a loop that could be faulty. You can also use time.sleep(n) to add delays. For more details see https://www.yelp.com/developers/documentation/v3/rate_limiting.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Below is sample code that you can use to help you deal with the pagination parameter and bring all of the functions together.***\n",
    "\n",
    "\n",
    "***Also, something might cause your code to break while it is running. You don't want to constantly repull the same data when this happens, so you should insert the data into the database as you call and parse it, not after you have all of the data***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable  to keep track of which result you are in. \n",
    "cur = 0\n",
    "\n",
    "#set up a while loop to go through and grab the result \n",
    "while cur < num and cur < 1000:\n",
    "    #set the offset parameter to be where you currently are in the results \n",
    "    url_params['offset'] = cur\n",
    "    #make your API call with the new offset number\n",
    "    results = yelp_call(url_params, api_key)\n",
    "    \n",
    "    #after you get your results you can now use your function to parse those results\n",
    "    parsed_results = parse_results(results)\n",
    "    \n",
    "    # use your function to insert your parsed results into the db\n",
    "    db_insert(parsed_results)\n",
    "    #increment the counter by 50 to move on to the next results\n",
    "    cur += 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
